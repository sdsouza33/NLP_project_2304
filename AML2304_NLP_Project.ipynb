{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data file reading\n",
    "try:\n",
    "    pse_isr_df=pd.read_csv(\"D:\\\\DSMM\\\\Term3\\\\bhavik\\\\Project\\\\pse_isr_reddit_comments.csv\")\n",
    "except Exception as e:\n",
    "    print(\"Exception while reading file\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 652892 entries, 0 to 652891\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   comment_id    652892 non-null  object\n",
      " 1   score         652892 non-null  int64 \n",
      " 2   self_text     652890 non-null  object\n",
      " 3   subreddit     652892 non-null  object\n",
      " 4   created_time  652892 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 24.9+ MB\n"
     ]
    }
   ],
   "source": [
    "#Data Exploration\n",
    "pse_isr_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    &gt;Microplastics have contaminated every corn...\n",
       "1    No I mean for the past 15 years prior to Octob...\n",
       "2    The West needs to stop playing Daddy and stepp...\n",
       "3                                Israel was a mistake.\n",
       "4    It’s the kind of argument you expect from Euro...\n",
       "Name: self_text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pse_isr_df['self_text'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of null values in the DataFrame:  comment_id      0\n",
      "score           0\n",
      "self_text       2\n",
      "subreddit       0\n",
      "created_time    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "comment_id      652890\n",
       "score           652890\n",
       "self_text       652890\n",
       "subreddit       652890\n",
       "created_time    652890\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_counts = pse_isr_df.isnull().sum()\n",
    "print(\"Total number of null values in the DataFrame: \", null_counts)\n",
    "pse_isr_df=pse_isr_df.dropna()\n",
    "pse_isr_df.count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>score</th>\n",
       "      <th>self_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_time</th>\n",
       "      <th>vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k8ponkf</td>\n",
       "      <td>1</td>\n",
       "      <td>&amp;gt;Microplastics have contaminated every corn...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>2023-11-10 23:13:48+00:00</td>\n",
       "      <td>Upvote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k8pokm4</td>\n",
       "      <td>1</td>\n",
       "      <td>No I mean for the past 15 years prior to Octob...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-11-10 23:13:14+00:00</td>\n",
       "      <td>Upvote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k8pogl6</td>\n",
       "      <td>1</td>\n",
       "      <td>The West needs to stop playing Daddy and stepp...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-11-10 23:12:28+00:00</td>\n",
       "      <td>Upvote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k8pogi2</td>\n",
       "      <td>1</td>\n",
       "      <td>Israel was a mistake.</td>\n",
       "      <td>worldnewsvideo</td>\n",
       "      <td>2023-11-10 23:12:26+00:00</td>\n",
       "      <td>Upvote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k8pofhz</td>\n",
       "      <td>1</td>\n",
       "      <td>It’s the kind of argument you expect from Euro...</td>\n",
       "      <td>AskMiddleEast</td>\n",
       "      <td>2023-11-10 23:12:15+00:00</td>\n",
       "      <td>Upvote</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id  score                                          self_text  \\\n",
       "0    k8ponkf      1  &gt;Microplastics have contaminated every corn...   \n",
       "1    k8pokm4      1  No I mean for the past 15 years prior to Octob...   \n",
       "2    k8pogl6      1  The West needs to stop playing Daddy and stepp...   \n",
       "3    k8pogi2      1                              Israel was a mistake.   \n",
       "4    k8pofhz      1  It’s the kind of argument you expect from Euro...   \n",
       "\n",
       "         subreddit               created_time    vote  \n",
       "0        worldnews  2023-11-10 23:13:48+00:00  Upvote  \n",
       "1  IsraelPalestine  2023-11-10 23:13:14+00:00  Upvote  \n",
       "2  IsraelPalestine  2023-11-10 23:12:28+00:00  Upvote  \n",
       "3   worldnewsvideo  2023-11-10 23:12:26+00:00  Upvote  \n",
       "4    AskMiddleEast  2023-11-10 23:12:15+00:00  Upvote  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Added new column 'vote' which shows upvote and downvote for the comment based on the score.\n",
    "pse_isr_df['vote']=pse_isr_df['score'].apply(lambda x: 'Upvote' if x>0 else 'Downvote')\n",
    "#pse_isr_df['vote']=pse_isr_df['score'].apply(lambda x: 'Upvote' if x>0 else ('Downvote' if x<0 else 'Neutral'))\n",
    "pse_isr_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>score</th>\n",
       "      <th>self_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_time</th>\n",
       "      <th>vote</th>\n",
       "      <th>EncodedVote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k8ponkf</td>\n",
       "      <td>1</td>\n",
       "      <td>&amp;gt;Microplastics have contaminated every corn...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>2023-11-10 23:13:48+00:00</td>\n",
       "      <td>Upvote</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k8pokm4</td>\n",
       "      <td>1</td>\n",
       "      <td>No I mean for the past 15 years prior to Octob...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-11-10 23:13:14+00:00</td>\n",
       "      <td>Upvote</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k8pogl6</td>\n",
       "      <td>1</td>\n",
       "      <td>The West needs to stop playing Daddy and stepp...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-11-10 23:12:28+00:00</td>\n",
       "      <td>Upvote</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k8pogi2</td>\n",
       "      <td>1</td>\n",
       "      <td>Israel was a mistake.</td>\n",
       "      <td>worldnewsvideo</td>\n",
       "      <td>2023-11-10 23:12:26+00:00</td>\n",
       "      <td>Upvote</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k8pofhz</td>\n",
       "      <td>1</td>\n",
       "      <td>It’s the kind of argument you expect from Euro...</td>\n",
       "      <td>AskMiddleEast</td>\n",
       "      <td>2023-11-10 23:12:15+00:00</td>\n",
       "      <td>Upvote</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id  score                                          self_text  \\\n",
       "0    k8ponkf      1  &gt;Microplastics have contaminated every corn...   \n",
       "1    k8pokm4      1  No I mean for the past 15 years prior to Octob...   \n",
       "2    k8pogl6      1  The West needs to stop playing Daddy and stepp...   \n",
       "3    k8pogi2      1                              Israel was a mistake.   \n",
       "4    k8pofhz      1  It’s the kind of argument you expect from Euro...   \n",
       "\n",
       "         subreddit               created_time    vote  EncodedVote  \n",
       "0        worldnews  2023-11-10 23:13:48+00:00  Upvote            1  \n",
       "1  IsraelPalestine  2023-11-10 23:13:14+00:00  Upvote            1  \n",
       "2  IsraelPalestine  2023-11-10 23:12:28+00:00  Upvote            1  \n",
       "3   worldnewsvideo  2023-11-10 23:12:26+00:00  Upvote            1  \n",
       "4    AskMiddleEast  2023-11-10 23:12:15+00:00  Upvote            1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using Labelencoder to convert the labels of upvote as 1 and Downvote to 0.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "vote = pse_isr_df['vote'].values\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoded_vote = encoder.fit_transform(vote)\n",
    "pse_isr_df['EncodedVote']=encoded_vote\n",
    "pse_isr_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    569948\n",
       "0     82942\n",
       "Name: EncodedVote, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check whether the data is balanced or not\n",
    "pse_isr_df['EncodedVote'].value_counts()\n",
    "\n",
    "#Data is highly imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         microplastics contaminated every corner planet...\n",
       "1                       mean past 15 year prior october 7th\n",
       "2         west need stop playing daddy stepping set coun...\n",
       "3                                            israel mistake\n",
       "4         kind argument expect european people moving re...\n",
       "                                ...                        \n",
       "652887                                           u bullshit\n",
       "652888    united state dotted west bank gaza strip altho...\n",
       "652889    country sometimes map adapt country view matte...\n",
       "652890    cant give something pretended support cynical ...\n",
       "652891    head islamic jihad denounced arab attempt norm...\n",
       "Name: clean_text, Length: 652890, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Cleaning before model building\n",
    "\n",
    "# Initialize the lemmatizer and stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    text = soup.get_text()\n",
    "    \n",
    "    # Remove special characters and lowercase the text\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text).lower()\n",
    "    \n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Lemmatization and removing stopwords\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Join the tokens back into a sentence\n",
    "    cleaned_text = ' '.join(tokens)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "pse_isr_df['clean_text'] = pse_isr_df['self_text'].apply(clean_text)\n",
    "pse_isr_df['clean_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = pse_isr_df['clean_text'].values\n",
    "y = pse_isr_df['EncodedVote'].values\n",
    "Xtrain,Xtest,ytrain,ytest = train_test_split(X,y,test_size=0.3)\n",
    "Xtrain_CV = vectorizer.fit_transform(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before SMOTE: Counter({1: 399104, 0: 57919})\n",
      "Class distribution after SMOTE: Counter({1: 399104, 0: 399104})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE  \n",
    "from collections import Counter\n",
    "\n",
    "print(\"Class distribution before SMOTE:\", Counter(ytrain))\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE()\n",
    "Xtrain_sm, ytrain_sm = smote.fit_resample(Xtrain_CV, ytrain)\n",
    "\n",
    "# Display the class distribution after SMOTE\n",
    "print(\"Class distribution after SMOTE:\", Counter(ytrain_sm))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB = MultinomialNB()\n",
    "NB.fit(Xtrain_sm,ytrain_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_CV = vectorizer.transform(Xtest)\n",
    "Ypredict = NB.predict(Xtest_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score::: 68.6026742636585\n",
      "Classification Report:::\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.37      0.23     25023\n",
      "           1       0.89      0.73      0.80    170844\n",
      "\n",
      "    accuracy                           0.69    195867\n",
      "   macro avg       0.53      0.55      0.52    195867\n",
      "weighted avg       0.80      0.69      0.73    195867\n",
      "\n",
      "Confusion Matrix:::\n",
      " [[  9156  15867]\n",
      " [ 45630 125214]]\n"
     ]
    }
   ],
   "source": [
    "accuracyScore = accuracy_score(ytest,Ypredict)*100\n",
    "print(\"Accuracy Score:::\",accuracyScore)\n",
    "report = classification_report(ytest, Ypredict)\n",
    "print(\"Classification Report:::\\n\",report)\n",
    "\n",
    "confusion = confusion_matrix(ytest, Ypredict)\n",
    "print(\"Confusion Matrix:::\\n\", confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downvote\n"
     ]
    }
   ],
   "source": [
    "msg = input(\"Enter Message: \")\n",
    "msgInput = vectorizer.transform([msg])\n",
    "predict = NB.predict(msgInput)\n",
    "\n",
    "if(predict==0):\n",
    "    print(\"Downvote\")\n",
    "else:\n",
    "    print(\"Upvote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karth\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.6466684025384573\n",
      "Precision score:  0.8827654254037117\n",
      "Recall score:  0.6860235068249397\n",
      "F1 score:  0.7720577579278817\n",
      "\n",
      "Confusion Matrix :\n",
      " [[  9458  15565]\n",
      " [ 53641 117203]]\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression().fit(Xtrain_sm, ytrain_sm)\n",
    "\n",
    "predictions = clf.predict(Xtest_CV)\n",
    "\n",
    "print('Accuracy score: ', format(accuracy_score(ytest, predictions)))\n",
    "print('Precision score: ', format(precision_score(ytest, predictions)))\n",
    "print('Recall score: ', format(recall_score(ytest, predictions)))\n",
    "print('F1 score: ', format(f1_score(ytest, predictions)))\n",
    "print('\\nConfusion Matrix :\\n', confusion_matrix(ytest, predictions)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
